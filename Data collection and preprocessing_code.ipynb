{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60185da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import snscrape.modules.twitter as sntwitter # interact with the data and tweet objects after scraping.\n",
    "import numpy as np # numpy adds support for large multidimensional arrays and matrices and collection of high level mathematical functions.\n",
    "import matplotlib.pyplot as plt # matplot for data viz\n",
    "import seaborn as sns # for viz\n",
    "\n",
    "import nltk #natural language toolkit- for identifying and tagging parts of speech found in the text of natural language like English.\n",
    "from nltk.tokenize import word_tokenize # nltk.tokenize -  breaking down vast data into smaller chunks\n",
    "from nltk.stem import WordNetLemmatizer # nltk.stem - to determine domain vocabularies in domain analysis.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "import textblob\n",
    "from textblob import TextBlob # textblob - sentiment analyzer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from emot.emo_unicode import UNICODE_EMOJI\n",
    "\n",
    "porter = PorterStemmer()\n",
    "# porter to remove 'es' etc from words\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "# lemmatizer to return base form of a word from dictionary\n",
    "\n",
    "from wordcloud import ImageColorGenerator\n",
    "from PIL import Image\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268fdc5",
   "metadata": {},
   "source": [
    "# Data Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(#travel OR #travelling Of #tourism OR #ttot OR #TTOT OR #trip of #vacation OR #wanderlust OR #holiday) lang:en'\n",
    "tweets=[]\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    tweets.append([tweet.date, tweet.id, tweet.user.username, tweet.sourceLabel, tweet.user.location,\n",
    "                    tweet.content, tweet.likeCount, tweet.retweetCount, tweet.hashtags, tweet.mentionedUsers])\n",
    "df = pd.DataFrame(tweets, columns=['Date', 'ID', 'username', 'source', 'location', 'tweet', 'num_of_likes',\n",
    "                                   'num_of_retweet', 'hashtags', 'mentions'])\n",
    "df.to_csv(\"travel_tweets_full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be139b6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>username</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "      <th>num_of_likes</th>\n",
       "      <th>num_of_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-01 05:17:18+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>cliff_89</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>BLOG LINK: https://t.co/0MmGQPVcGs\\n\\n#Palace ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Palace', 'Shirvanshahs', 'Icherisheher', 'Ol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-01 02:30:00+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>trusttravel84</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Mumbai Maharashtra India</td>\n",
       "      <td>Uncover the Wonders of Turkey and create memor...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['travel', 'traveling', 'vacation', 'visiting'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-01 00:59:28+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>readtwtr</td>\n",
       "      <td>Revive Social App</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Geneva Exploring the Best of it: What to See a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['bucketlist', 'explore', 'ttot', 'travelblogg...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-03-31 22:08:00+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>TRAVOH_travel</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Discover The Historic City Of Lucca, Italy\\n#T...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['TRAVOH', 'Solespire', 'Italy', 'Italian', 'L...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-03-31 22:02:00+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>tipplertravel</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Vietnam is a pretty travel-worthy country. Thi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['vietnam', 'halongbay', 'unescoworldheritage'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Date            ID       username  \\\n",
       "0           0  2023-04-01 05:17:18+00:00  1.640000e+18       cliff_89   \n",
       "1           1  2023-04-01 02:30:00+00:00  1.640000e+18  trusttravel84   \n",
       "2           2  2023-04-01 00:59:28+00:00  1.640000e+18       readtwtr   \n",
       "3           3  2023-03-31 22:08:00+00:00  1.640000e+18  TRAVOH_travel   \n",
       "4           4  2023-03-31 22:02:00+00:00  1.640000e+18  tipplertravel   \n",
       "\n",
       "              source                  location  \\\n",
       "0    Twitter Web App                 Singapore   \n",
       "1    Twitter Web App  Mumbai Maharashtra India   \n",
       "2  Revive Social App                 Worldwide   \n",
       "3          TweetDeck                 Worldwide   \n",
       "4    Twitter Web App              New York, NY   \n",
       "\n",
       "                                               tweet  num_of_likes  \\\n",
       "0  BLOG LINK: https://t.co/0MmGQPVcGs\\n\\n#Palace ...           0.0   \n",
       "1  Uncover the Wonders of Turkey and create memor...           1.0   \n",
       "2  Geneva Exploring the Best of it: What to See a...           0.0   \n",
       "3  Discover The Historic City Of Lucca, Italy\\n#T...           0.0   \n",
       "4  Vietnam is a pretty travel-worthy country. Thi...           0.0   \n",
       "\n",
       "   num_of_retweet                                           hashtags mentions  \n",
       "0             0.0  ['Palace', 'Shirvanshahs', 'Icherisheher', 'Ol...      NaN  \n",
       "1             1.0  ['travel', 'traveling', 'vacation', 'visiting'...      NaN  \n",
       "2             0.0  ['bucketlist', 'explore', 'ttot', 'travelblogg...      NaN  \n",
       "3             0.0  ['TRAVOH', 'Solespire', 'Italy', 'Italian', 'L...      NaN  \n",
       "4             0.0  ['vietnam', 'halongbay', 'unescoworldheritage'...      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset:\n",
    "data=pd.read_csv(r\"C:\\Users\\Megha\\jupyter\\SYNOPSIS\\travel_tweets_full.csv\")\n",
    "data=pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed4cf9c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets extracted:  81705\n"
     ]
    }
   ],
   "source": [
    "# total no. of tweets extracted\n",
    "print('no. of tweets extracted: ',data.tweet.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0256c3",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f958462",
   "metadata": {},
   "source": [
    "### Removing null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe398a94",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of rows with empty cells in tweet column:  7\n"
     ]
    }
   ],
   "source": [
    "print('no. of rows with empty cells in tweet column: ',data.tweet.isnull().sum())\n",
    "data = data.dropna(subset=['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70275a",
   "metadata": {},
   "source": [
    "### Converting to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1366cc29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_lowercase(column):\n",
    "    column = column.str.lower()\n",
    "    return column\n",
    "\n",
    "data['processed_clean_tweets'] = convert_lowercase(data['tweet']) # creating new column to store clean and processed tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8861d6",
   "metadata": {},
   "source": [
    "### Cleaning and pre-processing Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e15697",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "wl = WordNetLemmatizer()\n",
    "mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "           \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "           \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \n",
    "           \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "           \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "           \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \n",
    "           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\n",
    "           \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "           \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "           \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "           \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "           \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \n",
    "           \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "           \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "           \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "           \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\n",
    "           \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \n",
    "           \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \n",
    "           \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
    "           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \n",
    "           \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "           \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "           \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "           \"what'll\": \"what will\", \"what'll've\": \"what will have\",\"what're\": \"what are\",  \n",
    "           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \n",
    "           \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
    "           \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "           \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "           \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "           \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \n",
    "           \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \n",
    "           \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b42106a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a function t clean and process tweets\n",
    "def clean_process_text(text,lemmatize = True):\n",
    "    soup = BeautifulSoup(text, \"html.parser\") #remove html tags\n",
    "    text = soup.get_text()\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")]) #expanding chatwords and contracts clearing contractions\n",
    "    emoji_clean= re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_clean.sub(r'',text)\n",
    "    text = re.sub(r'\\.(?=\\S)', '. ',text) #add space after full stop\n",
    "    text = re.sub(r'http\\S+', '', text) #remove urls\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation]) #remove punctuation\n",
    "    #tokens = re.split('\\W+', text) #create tokens\n",
    "    if lemmatize:\n",
    "        text = \" \".join([wl.lemmatize(word) for word in text.split() if word not in stop and word.isalpha()]) #lemmatize\n",
    "    else:\n",
    "        text = \" \".join([word for word in text.split() if word not in stop and word.isalpha()]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee22d64",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a copy of original data:\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9ba5d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data['processed_clean_tweets'] = data['processed_clean_tweets'].astype(str)\n",
    "data['processed_clean_tweets'] = data['processed_clean_tweets'].apply(clean_process_text,lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14832ece",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_string = data['processed_clean_tweets'].tolist()\n",
    "tweets_string = \" \".join(tweets_string) # convert the tweet text into a string separate with \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc44885",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>username</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "      <th>num_of_likes</th>\n",
       "      <th>num_of_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>processed_clean_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-01 05:17:18+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>cliff_89</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>BLOG LINK: https://t.co/0MmGQPVcGs\\n\\n#Palace ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Palace', 'Shirvanshahs', 'Icherisheher', 'Ol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blog link palace shirvanshahs within icherishe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-01 02:30:00+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>trusttravel84</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Mumbai Maharashtra India</td>\n",
       "      <td>Uncover the Wonders of Turkey and create memor...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['travel', 'traveling', 'vacation', 'visiting'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncover wonder turkey create memory last lifet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-01 00:59:28+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>readtwtr</td>\n",
       "      <td>Revive Social App</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Geneva Exploring the Best of it: What to See a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['bucketlist', 'explore', 'ttot', 'travelblogg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>geneva exploring best see adventure bucketlist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-03-31 22:08:00+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>TRAVOH_travel</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Discover The Historic City Of Lucca, Italy\\n#T...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['TRAVOH', 'Solespire', 'Italy', 'Italian', 'L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discover historic city lucca italy travoh sole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-03-31 22:02:00+00:00</td>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>tipplertravel</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Vietnam is a pretty travel-worthy country. Thi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['vietnam', 'halongbay', 'unescoworldheritage'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vietnam pretty travelworthy country ha long ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Date            ID       username  \\\n",
       "0           0  2023-04-01 05:17:18+00:00  1.640000e+18       cliff_89   \n",
       "1           1  2023-04-01 02:30:00+00:00  1.640000e+18  trusttravel84   \n",
       "2           2  2023-04-01 00:59:28+00:00  1.640000e+18       readtwtr   \n",
       "3           3  2023-03-31 22:08:00+00:00  1.640000e+18  TRAVOH_travel   \n",
       "4           4  2023-03-31 22:02:00+00:00  1.640000e+18  tipplertravel   \n",
       "\n",
       "              source                  location  \\\n",
       "0    Twitter Web App                 Singapore   \n",
       "1    Twitter Web App  Mumbai Maharashtra India   \n",
       "2  Revive Social App                 Worldwide   \n",
       "3          TweetDeck                 Worldwide   \n",
       "4    Twitter Web App              New York, NY   \n",
       "\n",
       "                                               tweet  num_of_likes  \\\n",
       "0  BLOG LINK: https://t.co/0MmGQPVcGs\\n\\n#Palace ...           0.0   \n",
       "1  Uncover the Wonders of Turkey and create memor...           1.0   \n",
       "2  Geneva Exploring the Best of it: What to See a...           0.0   \n",
       "3  Discover The Historic City Of Lucca, Italy\\n#T...           0.0   \n",
       "4  Vietnam is a pretty travel-worthy country. Thi...           0.0   \n",
       "\n",
       "   num_of_retweet                                           hashtags mentions  \\\n",
       "0             0.0  ['Palace', 'Shirvanshahs', 'Icherisheher', 'Ol...      NaN   \n",
       "1             1.0  ['travel', 'traveling', 'vacation', 'visiting'...      NaN   \n",
       "2             0.0  ['bucketlist', 'explore', 'ttot', 'travelblogg...      NaN   \n",
       "3             0.0  ['TRAVOH', 'Solespire', 'Italy', 'Italian', 'L...      NaN   \n",
       "4             0.0  ['vietnam', 'halongbay', 'unescoworldheritage'...      NaN   \n",
       "\n",
       "                              processed_clean_tweets  \n",
       "0  blog link palace shirvanshahs within icherishe...  \n",
       "1  uncover wonder turkey create memory last lifet...  \n",
       "2  geneva exploring best see adventure bucketlist...  \n",
       "3  discover historic city lucca italy travoh sole...  \n",
       "4  vietnam pretty travelworthy country ha long ba...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b69d45b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of preprocessed tweets after cleaning and preprocessing:  81705\n"
     ]
    }
   ],
   "source": [
    "print('no. of preprocessed tweets after cleaning and preprocessing: ',data.processed_clean_tweets.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a6644",
   "metadata": {},
   "source": [
    "data.to_csv('proccess_clean_syn.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
